{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi4D4Q7leC0a"
   },
   "source": [
    "# Image Processing with Deep Learning\n",
    "<a href=\"https://colab.research.google.com/github/ntu-dl-bootcamp/deep-learning-2024/blob/main/session3/session3_part1_instructor.ipynb\" target=\"_blank\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>\n",
    "\n",
    "Welcome to the third session of deep learning bootcamp.  Today we are going to focus on using deep learning for image processing.  Feel free to jot down any notes you have from today's session in this notebook and please feel free to modify and experiment with the code during today's exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avWdnFiWe9Py"
   },
   "source": [
    "## Excercise 1: Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fITfC3HAwrh"
   },
   "source": [
    "First we will perform edge detection on an image using manually designed kernel.  We have completed the the vertical edge detection for you.  First, we will download the image and display the original..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "ECo_5ZB37cmd",
     "outputId": "d9f32cec-56f1-48d3-e39d-4514b759f08b"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "ECo_5ZB37cmd",
     "outputId": "19df6be9-cc2a-411d-88d9-9ff5c7cbd241"
    }
   },
   "outputs": [],
   "source": [
    "# Import the libaries we will need\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Grab an image for us to practice (feel free to upload your own!)\n",
    "!gdown https://drive.google.com/uc?id=1Kwp1at4u00lOx0-bRELbdk8f1c_JgjQP -O Peppers.bmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "oTa0RB3rBdPq",
     "outputId": "9ffc4b82-2c84-43f8-f15c-ed407f0aef25"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "oTa0RB3rBdPq",
     "outputId": "b9c1971c-2d28-4f6d-88ae-660fa75fbcc0"
    }
   },
   "outputs": [],
   "source": [
    "img = Image.open('Peppers.bmp')                             # Open the image\n",
    "img = torchvision.transforms.functional.pil_to_tensor(img)  # Convert it to a tensor\n",
    "img = img.float()                                           # Convert from integer to floating point\n",
    "plt.imshow(img.squeeze().numpy(), cmap='gray')              # Use matplotlib to display the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbUogKP4CT7u"
   },
   "source": [
    "Now we will detect vertical edges in the image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "W8DcbalTe4N4",
     "outputId": "572c8a23-7ddd-4c38-b35e-89851e2a25ae"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "W8DcbalTe4N4",
     "outputId": "7e9f1d23-54b2-4140-ee61-73406f27e61b"
    }
   },
   "outputs": [],
   "source": [
    "vertical_filter = torch.nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    bias=None\n",
    ")\n",
    "\n",
    "vertical_filter.weight = torch.nn.Parameter(\n",
    "    torch.Tensor([[[\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ]]])\n",
    ")\n",
    "\n",
    "vertical_edges = vertical_filter(img.unsqueeze(0))\n",
    "vertical_edges = vertical_edges.detach().squeeze().numpy()\n",
    "plt.imshow(vertical_edges, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1TqRt2Jjl-u"
   },
   "source": [
    "Can you detect the horizontal edges?  Make a custom kernel below check the result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "V9z-rXmcjkpG",
     "outputId": "9fbb1fe0-ea34-4074-e115-ba68bc327111"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "V9z-rXmcjkpG",
     "outputId": "508ac363-db20-4a71-b750-f15abae9b9bc"
    }
   },
   "outputs": [],
   "source": [
    "horizontal_filter = torch.nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    bias=None\n",
    ")\n",
    "\n",
    "horizontal_filter.weight = torch.nn.Parameter(\n",
    "    torch.Tensor([[[\n",
    "        [1, 2, 1],\n",
    "        [0, 0, 0],\n",
    "        [-1, -2, -1]\n",
    "    ]]])\n",
    ")\n",
    "\n",
    "horizontal_edges = horizontal_filter(img.unsqueeze(0))\n",
    "horizontal_edges = horizontal_edges.detach().squeeze().numpy()\n",
    "plt.imshow(horizontal_edges, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-tyBOa_kEJz"
   },
   "source": [
    "Now can you combine the result of the two filters together to display all edges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 453
     },
     "id": "YU1wc6Ykjker",
     "outputId": "267e6c8a-1474-4154-9dac-1fad752e8f99"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 452
     },
     "id": "YU1wc6Ykjker",
     "outputId": "f28a8656-cc5c-4dd5-a4a7-b040d066a129"
    }
   },
   "outputs": [],
   "source": [
    "all_edges = horizontal_edges + vertical_edges\n",
    "plt.imshow(all_edges, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpcvHJvDb_XC"
   },
   "source": [
    "## Excercise 2: Parameters of A Convolution\n",
    "\n",
    "### 2a: input and output channels\n",
    "Define a convolutional filter with 4 input channels and 6 output channels.  What will the output shape be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "c1xCWu95cNZ9",
     "outputId": "5279ab1d-c996-4f82-a5f3-9ed575374ae5"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "c1xCWu95cNZ9",
     "outputId": "3334d539-4675-4c74-ec90-7501e1e32d9c"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace the line below with the correct initialization for conv.\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=4,\n",
    "    out_channels=6,\n",
    "    kernel_size=1\n",
    ")\n",
    "\n",
    "x = torch.rand([1, 4, 100, 100])\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ivP-AT4eGzB"
   },
   "source": [
    "### 2b: kernel size\n",
    "Define a convolution kernel with a kernel size of 7x9 and no padding. What will the output shape be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "hu-Tnv_aeGHj",
     "outputId": "e9f25139-0dc3-461f-fdb0-6c8ff46f56cf"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "hu-Tnv_aeGHj",
     "outputId": "cbee0d14-ab9d-4c78-9ea5-433c52dbcaa6"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace the line below with the correct initialization for conv.\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=16,\n",
    "    out_channels=32,\n",
    "    kernel_size=(7,9)\n",
    ")\n",
    "\n",
    "x = torch.rand([3, 16, 255, 255])\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_tax8OKeYn9"
   },
   "source": [
    "### 2c: padding\n",
    "Define a convolution kernel with size 3x3 and 1 pixel of padding.  What will the ouptut shape be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "GolkUgaVekMC",
     "outputId": "390a6502-f1fd-426a-f970-a9515070afeb"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "GolkUgaVekMC",
     "outputId": "8809551a-32f0-4484-fbed-8504e04698ea"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace the line below with the correct initialization for conv.\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=64,\n",
    "    out_channels=128,\n",
    "    kernel_size=3,\n",
    "    padding=1\n",
    ")\n",
    "\n",
    "x = torch.rand([32, 64, 64, 64])\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1YK1j14eswy"
   },
   "source": [
    "### 2d: stride\n",
    "\n",
    "Define a convolutional kernel with size 5x5 and stride 2.  What will the output shape be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "OJum221Ye7qU",
     "outputId": "cc9113f3-957f-4d0f-979c-43d3f60beee0"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "OJum221Ye7qU",
     "outputId": "14fbb604-1599-4d19-ba04-61b6fa07fffd"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace the line below with the correct initialization for conv.\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=64,\n",
    "    out_channels=128,\n",
    "    kernel_size=5,\n",
    "    padding=2,\n",
    "    stride=2\n",
    ")\n",
    "\n",
    "x = torch.rand([32, 64, 64, 64])\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiFpaoXDe942"
   },
   "source": [
    "### 2e: dilation\n",
    "Define a convolutional kernel with size 7x7 and stride 1, and dilation 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "9mM0KfzJe9Z4",
     "outputId": "af471eb4-721d-4e28-b235-776a7d827625"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "9mM0KfzJe9Z4",
     "outputId": "90788115-3a9c-4770-e2de-74e2f68185cf"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: replace the line below with the correct initialization for conv.\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=64,\n",
    "    out_channels=32,\n",
    "    kernel_size=7,\n",
    "    stride=1,\n",
    "    dilation=2\n",
    ")\n",
    "\n",
    "x = torch.rand([32, 64, 64, 64])\n",
    "y = conv(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jwsESxPfalJ"
   },
   "source": [
    "## Exercise 3: Image classification\n",
    "Now we will try to classify pictures of numbers by learning filters with a CNN.  We will need to import torchvision to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 178
     },
     "id": "m0Y5AHudCsFS",
     "outputId": "20b2d696-96b4-4cb8-ef4b-1096537076ce"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 177
     },
     "id": "m0Y5AHudCsFS",
     "outputId": "dd29119e-55e0-42c7-8de1-785e08d1ade7"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# Let's go ahead and seed the random number generator so that we can reproduce our results\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "mnist = torchvision.datasets.MNIST(\n",
    "    root='sample_data',\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "print(f'Total No. Images: {len(mnist)}')\n",
    "\n",
    "print('Sample of images with ground truth class data:')\n",
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "  ax[i].imshow(mnist[i][0].squeeze())\n",
    "  ax[i].set_xlabel(mnist[i][1])\n",
    "  ax[i].get_xaxis().set_ticks([])\n",
    "  ax[i].get_yaxis().set_ticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1wWObDjM0nl"
   },
   "source": [
    "### Exercise 3a: Splitting the Dataset\n",
    "Okay, we've downloaded our dataset and looked at some images.  Now let's split our dataset.  Can you create an 80-10-10 Train/Val/Test split?*italicized text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "Mw4AXzYzGyPx",
     "outputId": "07516fc4-0071-45b5-d255-6b8f7e142b84"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "Mw4AXzYzGyPx",
     "outputId": "bc5b70f0-eb4a-419e-b138-c3f8fb44afb5"
    }
   },
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    mnist,\n",
    "    [int(0.8 * len(mnist)), int(0.1 * len(mnist)), int(0.1 * len(mnist))]\n",
    ")\n",
    "print(f'No. Train Images: {len(train_set)}')\n",
    "print(f'No. Val Images: {len(val_set)}')\n",
    "print(f'No. Test Images: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LTl7hxdNvlF"
   },
   "source": [
    "### Exercise 3b: LeNet\n",
    "A neural network for LeNet is coded below, but it's missing its first convolution in the ```forward()``` method.  Can you complete it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22DbhSvheAeb"
   },
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    # First Convolution\n",
    "    self.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=4,\n",
    "        kernel_size=5,\n",
    "        stride=1,\n",
    "        padding=0\n",
    "    )\n",
    "    self.batch_norm1 = torch.nn.BatchNorm2d(4)\n",
    "    self.activation1 = torch.nn.ReLU()\n",
    "    self.pool1 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    # Second Convolution\n",
    "    self.conv2 = torch.nn.Conv2d(\n",
    "        in_channels=4,\n",
    "        out_channels=12,\n",
    "        kernel_size=5,\n",
    "        stride=1,\n",
    "        padding=0\n",
    "    )\n",
    "    self.batch_norm2 = torch.nn.BatchNorm2d(12)\n",
    "    self.activation2 = torch.nn.ReLU()\n",
    "    self.pool2 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    self.fully_connected1 = torch.nn.Linear(\n",
    "        in_features=4 * 4 * 12,\n",
    "        out_features=10\n",
    "    )\n",
    "    self.softmax = torch.nn.LogSoftmax()\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    # First Convolution\n",
    "    x = self.conv1(x)\n",
    "    x = self.batch_norm1(x)\n",
    "    x = self.activation1(x)\n",
    "    x = self.pool1(x)\n",
    "\n",
    "    # Second Convolution\n",
    "    x = self.conv2(x)\n",
    "    x = self.batch_norm2(x)\n",
    "    x = self.activation2(x)\n",
    "    x = self.pool2(x)\n",
    "\n",
    "    # Head\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.fully_connected1(x)\n",
    "    y_hat = self.softmax(x)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYUdtLWiOaLv"
   },
   "source": [
    "### Excercise 3c: Training\n",
    "Now we need to train our model.  First we will create data loaders, which take data from the dataset and feed it to our model one batch at a time.  We loop over the entire dataset for 10 epochs.  However, there's a problem: the code below isn't calculating our validation loss.  Can you fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "nxvsG0XbVtgb",
     "outputId": "829942d9-04b7-4691-bd88-cbe18aee1b01"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "nxvsG0XbVtgb",
     "outputId": "e5b120a5-031a-459e-ba4d-cf36b15fc520"
    }
   },
   "outputs": [],
   "source": [
    "# If we have a GPU, then use it\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Create an instance of the model and put it on the GPU\n",
    "model = LeNet()\n",
    "model.to(device)\n",
    "\n",
    "# Create 2 dataloaders, one for training and one for validation\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=200,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "# We will use negative log likelihood loss\n",
    "loss_function = torch.nn.NLLLoss()\n",
    "\n",
    "# Let's use the Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training Loop\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(10):\n",
    "  train_loss.append(0)\n",
    "  val_loss.append(0)\n",
    "  # Training data\n",
    "  for data in train_loader:\n",
    "    # Get data from the loader and give it to the network\n",
    "    x, y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_hat = model(x)\n",
    "\n",
    "    # Calculate loss\n",
    "    L = loss_function(y_hat, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Record our result\n",
    "    train_loss[-1] += L\n",
    "\n",
    "  # Cross validation\n",
    "  for data in val_loader:\n",
    "    x, y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "      y_hat = model(x)\n",
    "      L = loss_function(y_hat, y)\n",
    "      val_loss[-1] += L\n",
    "\n",
    "  print(f'Epoch: {epoch} --- Training Loss: {train_loss[-1]:.2f} --- Val Loss: {val_loss[-1]:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu8RIg7QRHhu"
   },
   "source": [
    "### Exercise 3d: Test the model\n",
    "Can you calculate the total number of correct predictions your model makes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "DXFWjWbhyhKX",
     "outputId": "02e8eca6-a455-4bea-cff5-7e9391ee51b9"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "DXFWjWbhyhKX",
     "outputId": "3a8aa4ef-6241-4601-ec1d-78767d19eb27"
    }
   },
   "outputs": [],
   "source": [
    "# Create a test data loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=200\n",
    ")\n",
    "\n",
    "total_predictions = 0\n",
    "total_correct = 0\n",
    "for data in train_loader:\n",
    "  x, y = data\n",
    "  x = x.to(device)\n",
    "  y = y.to(device)\n",
    "  with torch.no_grad():\n",
    "    y_hat = model(x)\n",
    "    total_correct += torch.sum(torch.argmax(y_hat, 1) == y)\n",
    "    total_predictions += y_hat.shape[0]\n",
    "\n",
    "print(f'Accuracy: {100 * total_correct/total_predictions:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM8uyv2QRt7R"
   },
   "source": [
    "Now let's visualize our predictions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 142
     },
     "id": "nGMyUOUk1DzZ",
     "outputId": "e6fe1e26-b237-423e-e81f-a531bb0eae1d"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 197
     },
     "id": "nGMyUOUk1DzZ",
     "outputId": "ca18c411-ae81-4d50-ee02-8434859ac73f"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize Predictions\n",
    "fig, ax = plt.subplots(1,5)\n",
    "for i in range(5):\n",
    "  ax[i].imshow(mnist[i][0].squeeze())\n",
    "\n",
    "  with torch.no_grad():\n",
    "    y_hat = model(mnist[i][0].unsqueeze(0).to(device))\n",
    "    ax[i].set_xlabel(f'GT: {mnist[i][1]}, NN: {torch.argmax(y_hat, 1).item()}')\n",
    "\n",
    "  ax[i].get_xaxis().set_ticks([])\n",
    "  ax[i].get_yaxis().set_ticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xWCH01tR-hh"
   },
   "source": [
    "We can also visualize the features we learned.  For more information on explaining what a CNN learned, check out [this blog](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 144
     },
     "id": "cnWwUJMv2cG5",
     "outputId": "557dbeec-1443-4e40-900f-1c5f10cee8df"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 144
     },
     "id": "cnWwUJMv2cG5",
     "outputId": "9bb8bf4c-068d-4ea2-eac1-c585c5aed838"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,4)\n",
    "for i in range(4):\n",
    "  filter = model.cpu().conv1.weight[i,0,:,:].squeeze().detach().numpy()\n",
    "  ax[i].imshow(filter)\n",
    "  ax[i].get_xaxis().set_ticks([])\n",
    "  ax[i].get_yaxis().set_ticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HL5i__nUTPL5"
   },
   "source": [
    "### Exercise 3e: Can you do better?\n",
    "Now see if you can modify the training code or the architecture above to get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYQy5UDsTzVG"
   },
   "source": [
    "## Exercise 4: Loading a Pretrained Model\n",
    "Now we will load a pretrained model (Resnet 18) trained on Imagenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "khhk86ONT3Ka",
     "outputId": "be6d28eb-7f05-431c-f5b7-ff8855f565f6"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "khhk86ONT3Ka",
     "outputId": "7470750f-38b1-4288-b6e1-36967845d646"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYrlijWMUDTu"
   },
   "source": [
    "First, we will grab an image of a dog and visualize it to know what we're working with.  Here we are using urllib to download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 453
     },
     "id": "sBPFe1xScnvr",
     "outputId": "c7d4c375-f55c-428b-c310-759a6b4f715c"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 452
     },
     "id": "sBPFe1xScnvr",
     "outputId": "46b69419-848c-4107-9c03-38937e94a063"
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "urllib.request.urlretrieve(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "\n",
    "img = Image.open(\"dog.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifmVhYogUciF"
   },
   "source": [
    "### Exercise 4a: Inferencing a Pretrained Model\n",
    "Can you complete the code to classify the image of the dog using Resnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "OXmW9l25jIY6",
     "outputId": "204e1ce2-ab3a-43ad-92a9-2cd092ab4d2a"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "OXmW9l25jIY6",
     "outputId": "27650b27-748d-4ae4-b242-eb44c7ced05c"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "x = preprocess(img)\n",
    "\n",
    "y = model(x.unsqueeze(0))\n",
    "probabilities = torch.nn.functional.softmax(y[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m08nUYVVCMN"
   },
   "source": [
    "Now let's interpret those results.  Each dimension in the output array corresponds to one class, but Imagenet has 1000 classes.  Luckily there is a list that maps Imagenet dimension number to classes.  Let's use it to find out what we actually predicted..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "olvrvsNPkaQS",
     "outputId": "396786d3-da57-4e9e-d599-fec71444e02b"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "olvrvsNPkaQS",
     "outputId": "4dd8b6c1-59ef-44b0-d15a-f3f2aa08642d"
    }
   },
   "outputs": [],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
    "\n",
    "# Load the file as a list in python\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Show the top 5 most likely 5 categories\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JH1gh3WVhn3"
   },
   "source": [
    "Now we're going to grab a dataset of different Pokemon.  This dataset comes in a zip format, so we'll use some new libraries to extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbMfQQDUlnXu"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://osf.io/u4njm/download', stream=True)\n",
    "archive = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIX8Q8RYYuNC"
   },
   "source": [
    "### Exercise 4b: Fine-tuning Dataset\n",
    "Before we can perform transfer learning on the Pokemon dataset, we need to split between training, validation, and test.  Can you complete the code below to make that happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "id": "kC8kxrtKV8_4"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "kC8kxrtKV8_4",
     "outputId": "9e208824-89fe-44ee-b76c-b768db3ef5a8"
    }
   },
   "outputs": [],
   "source": [
    "preprocess = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.Resize((224, 224)),\n",
    "  torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "pokemon = torchvision.datasets.ImageFolder(\n",
    "  'small_pokemon_dataset',\n",
    "  transform=preprocess\n",
    ")\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "  pokemon,\n",
    "  [int(0.8 * len(pokemon)), int(0.1 * len(pokemon)), len(pokemon) - int(0.8 * len(pokemon)) - int(0.1 * len(pokemon))]\n",
    ")\n",
    "print(f'No. Train Images: {len(train_set)}')\n",
    "print(f'No. Val Images: {len(val_set)}')\n",
    "print(f'No. Test Images: {len(test_set)}')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=16\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrpJkeRMZY2L"
   },
   "source": [
    "### Excercise 4c: Modifying our pretrained model\n",
    "Resent comes with 1000 output neurons, but we only have 9 classes.  Can you replace the last layer of the model to only have 9 outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4jLpjb1ZOQh"
   },
   "outputs": [],
   "source": [
    "no_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(no_features, 9)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWaX0Um9Zz4K"
   },
   "source": [
    "### Excercise 4d: Training Loop\n",
    "Can you complete the code below to use cross-entropy loss during training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "x_IOmZtGmgPQ",
     "outputId": "eba8c48b-d5a5-4db4-ff01-a97bbdb420b3"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "x_IOmZtGmgPQ",
     "outputId": "d009adbe-f698-462a-be13-8cd883e7dee6"
    }
   },
   "outputs": [],
   "source": [
    "# Set up our optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Allow model gradients to be updated\n",
    "model.train()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(10):\n",
    "  train_loss.append(0)\n",
    "  val_loss.append(0)\n",
    "\n",
    "  # Train loop\n",
    "  for batch in train_loader:\n",
    "    x, y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    y_hat = model(x)\n",
    "    L = loss_function(y_hat, y)\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss[-1] += L\n",
    "\n",
    "  # Validation loop\n",
    "  for data in val_loader:\n",
    "    x, y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "      y_hat = model(x)\n",
    "      L = loss_function(y_hat, y)\n",
    "      val_loss[-1] += L\n",
    "\n",
    "  print(f'Epoch: {epoch} --- Training Loss: {train_loss[-1]:.2f} --- Val Loss: {val_loss[-1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDaRx4u-uD_A"
   },
   "source": [
    "### Exercise 4e: Prediction\n",
    "Let's take an image from our dataset.  How did we do at prediction.  Can you complete the code below to find out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "nIQ8HeogudJU",
     "outputId": "5b9dbe41-d844-4de6-ed98-923e6fe394a5"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/"
     },
     "id": "nIQ8HeogudJU",
     "outputId": "31477ca3-b330-43b3-b9fa-dc9164cb516b"
    }
   },
   "outputs": [],
   "source": [
    "img = Image.open('small_pokemon_dataset/Blastoise/03bc036b642d4873985399cebfd0bb64.jpg')\n",
    "x = preprocess(img).to(device)\n",
    "\n",
    "y = model(x.unsqueeze(0))\n",
    "probabilities = torch.nn.functional.softmax(y[0], dim=0)\n",
    "for name, idx in pokemon.class_to_idx.items():\n",
    "  print(f'{name}: {100 * probabilities[idx]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_1uVcWovNaf"
   },
   "source": [
    "## Exercise 5: Segmentation\n",
    "Now we will use UNET, an early model for image segmentation to look at identifying brain tumors in CT scan images.  First we will load the model from torch hub and download an image to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "id": "6vKirmaSaoxR"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 452
     },
     "id": "6vKirmaSaoxR",
     "outputId": "7cb2b354-9d3e-4b73-f123-8995e6e595a5"
    }
   },
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "# Load Test Image\n",
    "urllib.request.urlretrieve(\"https://github.com/mateuszbuda/brain-segmentation-pytorch/raw/master/assets/TCGA_CS_4944.png\", \"TCGA_CS_4944.png\")\n",
    "img = Image.open(\"TCGA_CS_4944.png\")\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahKrWKEwbTwD"
   },
   "source": [
    "The code to preprocess the image is provided for you below, can you preprocess the image and inference the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "local_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 871
     },
     "id": "X_ADDlGYvReS",
     "outputId": "937d2555-ca09-4f0b-efa0-7ed549fdc2f9"
    },
    "remote_metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
      "height": 435
     },
     "id": "X_ADDlGYvReS",
     "outputId": "06b50816-4e21-4a1c-c75a-1dfdc3a025b4"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "mu, sig = numpy.mean(img, axis=(0, 1)), numpy.std(img, axis=(0, 1))\n",
    "preprocess = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=mu, std=sig),\n",
    "])\n",
    "x = preprocess(img)\n",
    "\n",
    "y = model(x.unsqueeze(0))\n",
    "\n",
    "plt.imshow(y.squeeze(0,1).detach().numpy())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
